{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eef91a4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-04T10:13:27.285725Z",
     "iopub.status.busy": "2023-07-04T10:13:27.285031Z",
     "iopub.status.idle": "2023-07-04T10:13:27.586428Z",
     "shell.execute_reply": "2023-07-04T10:13:27.585492Z",
     "shell.execute_reply.started": "2023-07-04T10:13:27.285687Z"
    },
    "papermill": {
     "duration": 0.010333,
     "end_time": "2023-07-15T08:49:51.338910",
     "exception": false,
     "start_time": "2023-07-15T08:49:51.328577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Starter Code - Classification on Unlabeled and Mislabeled Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914acaa2",
   "metadata": {
    "papermill": {
     "duration": 0.009291,
     "end_time": "2023-07-15T08:49:51.358332",
     "exception": false,
     "start_time": "2023-07-15T08:49:51.349041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Import Libraries </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4412d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:51.380035Z",
     "iopub.status.busy": "2023-07-15T08:49:51.379189Z",
     "iopub.status.idle": "2023-07-15T08:49:55.298317Z",
     "shell.execute_reply": "2023-07-15T08:49:55.297315Z"
    },
    "papermill": {
     "duration": 3.932795,
     "end_time": "2023-07-15T08:49:55.300851",
     "exception": false,
     "start_time": "2023-07-15T08:49:51.368056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d461e",
   "metadata": {
    "papermill": {
     "duration": 0.009021,
     "end_time": "2023-07-15T08:49:55.319838",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.310817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Training Configuration </h4>\n",
    "You should experiment with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f89e82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.339676Z",
     "iopub.status.busy": "2023-07-15T08:49:55.338498Z",
     "iopub.status.idle": "2023-07-15T08:49:55.443384Z",
     "shell.execute_reply": "2023-07-15T08:49:55.441978Z"
    },
    "papermill": {
     "duration": 0.117211,
     "end_time": "2023-07-15T08:49:55.446027",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.328816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 420,\n",
    "          \"epochs\": 10,\n",
    "          \"img_size\": 64,\n",
    "          \"num_classes\": 30,\n",
    "          \"train_batch_size\": 128,\n",
    "          \"val_batch_size\": 128,\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"num_workers\": 2,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          # StepLR Scheduler hyperparameters\n",
    "          \"step_size\": 10,\n",
    "          \"gamma\": 0.95\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa276362",
   "metadata": {
    "papermill": {
     "duration": 0.008643,
     "end_time": "2023-07-15T08:49:55.464274",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.455631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Set seed for reproducibility </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67bc238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.485469Z",
     "iopub.status.busy": "2023-07-15T08:49:55.483742Z",
     "iopub.status.idle": "2023-07-15T08:49:55.499803Z",
     "shell.execute_reply": "2023-07-15T08:49:55.498914Z"
    },
    "papermill": {
     "duration": 0.028291,
     "end_time": "2023-07-15T08:49:55.501853",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.473562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "torch.cuda.manual_seed(CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3264e10",
   "metadata": {
    "papermill": {
     "duration": 0.008642,
     "end_time": "2023-07-15T08:49:55.519250",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.510608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Data Directories </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04108a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.539681Z",
     "iopub.status.busy": "2023-07-15T08:49:55.538817Z",
     "iopub.status.idle": "2023-07-15T08:49:55.544338Z",
     "shell.execute_reply": "2023-07-15T08:49:55.543423Z"
    },
    "papermill": {
     "duration": 0.017701,
     "end_time": "2023-07-15T08:49:55.546367",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.528666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = '/kaggle/input/classification-on-unlabeled-and-mislabeled-images/'\n",
    "TRAIN_LABELED_DIR = os.path.join(ROOT_DIR, 'train/train/labeled_images/')\n",
    "TRAIN_UNLABELED_DIR = os.path.join(ROOT_DIR, 'train/train/unlabeled_images/')\n",
    "TEST_DIR = os.path.join(ROOT_DIR, 'test/test/images/')\n",
    "SAVE_PATH = \"best_model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd812c4",
   "metadata": {
    "papermill": {
     "duration": 0.008547,
     "end_time": "2023-07-15T08:49:55.563406",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.554859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Read the CSV </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0929e0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.582473Z",
     "iopub.status.busy": "2023-07-15T08:49:55.582158Z",
     "iopub.status.idle": "2023-07-15T08:49:55.611339Z",
     "shell.execute_reply": "2023-07-15T08:49:55.610520Z"
    },
    "papermill": {
     "duration": 0.041237,
     "end_time": "2023-07-15T08:49:55.613424",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.572187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000.JPEG</td>\n",
       "      <td>250605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.JPEG</td>\n",
       "      <td>516810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000002.JPEG</td>\n",
       "      <td>289648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000003.JPEG</td>\n",
       "      <td>688319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000004.JPEG</td>\n",
       "      <td>964607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name  class_name\n",
       "0  000000.JPEG      250605\n",
       "1  000001.JPEG      516810\n",
       "2  000002.JPEG      289648\n",
       "3  000003.JPEG      688319\n",
       "4  000004.JPEG      964607"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(ROOT_DIR, 'train_annotations.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f52f7",
   "metadata": {
    "papermill": {
     "duration": 0.009215,
     "end_time": "2023-07-15T08:49:55.631955",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.622740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Create mapping for class_name </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6849db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.651585Z",
     "iopub.status.busy": "2023-07-15T08:49:55.650777Z",
     "iopub.status.idle": "2023-07-15T08:49:55.662933Z",
     "shell.execute_reply": "2023-07-15T08:49:55.661961Z"
    },
    "papermill": {
     "duration": 0.024237,
     "end_time": "2023-07-15T08:49:55.665022",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.640785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{250605: 0,\n",
       " 516810: 1,\n",
       " 289648: 2,\n",
       " 688319: 3,\n",
       " 964607: 4,\n",
       " 431115: 5,\n",
       " 517908: 6,\n",
       " 44558: 7,\n",
       " 665003: 8,\n",
       " 500192: 9,\n",
       " 477273: 10,\n",
       " 335856: 11,\n",
       " 158226: 12,\n",
       " 914948: 13,\n",
       " 690093: 14,\n",
       " 759848: 15,\n",
       " 28368: 16,\n",
       " 612747: 17,\n",
       " 812491: 18,\n",
       " 589958: 19,\n",
       " 436479: 20,\n",
       " 358316: 21,\n",
       " 339246: 22,\n",
       " 537498: 23,\n",
       " 146725: 24,\n",
       " 896857: 25,\n",
       " 877556: 26,\n",
       " 56639: 27,\n",
       " 648396: 28,\n",
       " 821885: 29}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = df.class_name.unique()\n",
    "class_to_index_mapping = {}\n",
    "index_to_class_mapping = {}\n",
    "for i in range(CONFIG['num_classes']):\n",
    "    class_to_index_mapping[class_names[i]] = i\n",
    "    index_to_class_mapping[i] = class_names[i]\n",
    "class_to_index_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d41a",
   "metadata": {
    "papermill": {
     "duration": 0.009329,
     "end_time": "2023-07-15T08:49:55.683936",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.674607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Dataset Class </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35278dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.705031Z",
     "iopub.status.busy": "2023-07-15T08:49:55.704204Z",
     "iopub.status.idle": "2023-07-15T08:49:55.713439Z",
     "shell.execute_reply": "2023-07-15T08:49:55.712593Z"
    },
    "papermill": {
     "duration": 0.022019,
     "end_time": "2023-07-15T08:49:55.715538",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.693519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path, data_dir, transform, dataset_type='train'):\n",
    "        self.transform = transform\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # Split training set into train and validation\n",
    "        train_data=df.sample(frac=0.8,random_state=CONFIG['seed'])\n",
    "        if dataset_type == 'train':\n",
    "            self.data = train_data\n",
    "        elif dataset_type == 'val':\n",
    "            self.data=df.drop(train_data.index)\n",
    "\n",
    "        # For submission use full training set\n",
    "        elif dataset_type == 'full-train':\n",
    "                self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        img_path = os.path.join(self.data_dir, row['image_name'])\n",
    "        img_label = class_to_index_mapping[row.class_name]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)        \n",
    "            \n",
    "        output = {'img': img, 'label': img_label}\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95a598b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.736451Z",
     "iopub.status.busy": "2023-07-15T08:49:55.735571Z",
     "iopub.status.idle": "2023-07-15T08:49:55.743202Z",
     "shell.execute_reply": "2023-07-15T08:49:55.742304Z"
    },
    "papermill": {
     "duration": 0.020701,
     "end_time": "2023-07-15T08:49:55.745391",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.724690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset for loading unlabeled set and test set\n",
    "\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.img_names = [filename for filename in sorted(os.listdir(self.data_dir))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.img_names[idx])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)        \n",
    "            \n",
    "        output = {'img': img, 'img_name': self.img_names[idx]}\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153525d",
   "metadata": {
    "papermill": {
     "duration": 0.009763,
     "end_time": "2023-07-15T08:49:55.765396",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.755633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Augmentations </h4>\n",
    "You should experiment with adding/removing transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae3d084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.786746Z",
     "iopub.status.busy": "2023-07-15T08:49:55.785192Z",
     "iopub.status.idle": "2023-07-15T08:49:55.793074Z",
     "shell.execute_reply": "2023-07-15T08:49:55.792281Z"
    },
    "papermill": {
     "duration": 0.019914,
     "end_time": "2023-07-15T08:49:55.795006",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.775092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(CONFIG['img_size']),\n",
    "    transforms.RandomResizedCrop(CONFIG['img_size']),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(CONFIG['img_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6360959",
   "metadata": {
    "papermill": {
     "duration": 0.009554,
     "end_time": "2023-07-15T08:49:55.813961",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.804407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Prepare Data loaders </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f777404e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.833197Z",
     "iopub.status.busy": "2023-07-15T08:49:55.832914Z",
     "iopub.status.idle": "2023-07-15T08:49:55.843439Z",
     "shell.execute_reply": "2023-07-15T08:49:55.842586Z"
    },
    "papermill": {
     "duration": 0.022546,
     "end_time": "2023-07-15T08:49:55.845547",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.823001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weak_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomCrop(size=32, padding=int(32*0.125), padding_mode='reflect'),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]) # weak transforms are just random shifting and flipping\n",
    "\n",
    "strong_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees = 90),\n",
    "    transforms.RandomVerticalFlip(p = 0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor = 1, p = 0.5),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomCrop(size=32, padding=int(32*0.125), padding_mode='reflect'),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.2),\n",
    "    transforms.RandomGrayscale(p = 0.2),\n",
    "#     transforms.Resize(CONFIG['img_size']),\n",
    "#     transforms.RandomResizedCrop(CONFIG['img_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "class TransformFixMatch(object):\n",
    "    def __init__(self, weak, strong):\n",
    "        self.weak = weak\n",
    "        self.strong = strong\n",
    "\n",
    "    def __call__(self, x):\n",
    "        weak = self.weak(x)\n",
    "        strong = self.strong(x)\n",
    "\n",
    "        return weak, strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64843036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.864634Z",
     "iopub.status.busy": "2023-07-15T08:49:55.864379Z",
     "iopub.status.idle": "2023-07-15T08:49:55.868604Z",
     "shell.execute_reply": "2023-07-15T08:49:55.867689Z"
    },
    "papermill": {
     "duration": 0.015986,
     "end_time": "2023-07-15T08:49:55.870637",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.854651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding the new transforms\n",
    "# cifar_labeled_trainset = CIFAR10SSL(root='./data', indexs = labeled_indices, train=True, transform = weak_transforms)\n",
    "# cifar_unlabeled_trainset = CIFAR10SSL(root='./data', indexs = unlabeled_indices, train=True, transform=TransformFixMatch(weak = weak_transforms, strong = strong_transforms))\n",
    "# cifar_testset = datasets.CIFAR10(root='./data', train=False, transform = val_transforms, download=False)\n",
    "\n",
    "# cifar_labeled_trainloader = DataLoader(cifar_labeled_trainset, batch_size=64, sampler = RandomSampler(cifar_labeled_trainset))\n",
    "# cifar_unlabeled_trainloader = DataLoader(cifar_unlabeled_trainset, batch_size=7 * 64, sampler = RandomSampler(cifar_unlabeled_trainset))\n",
    "# cifar_testloader = DataLoader(cifar_testset, batch_size=64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a92de68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.890311Z",
     "iopub.status.busy": "2023-07-15T08:49:55.889402Z",
     "iopub.status.idle": "2023-07-15T08:49:55.897814Z",
     "shell.execute_reply": "2023-07-15T08:49:55.896930Z"
    },
    "papermill": {
     "duration": 0.020312,
     "end_time": "2023-07-15T08:49:55.899830",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.879518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    train_set = CustomDataset(\n",
    "        csv_path = os.path.join(ROOT_DIR, 'train_annotations.csv'),\n",
    "        data_dir = TRAIN_LABELED_DIR,\n",
    "        transform = train_transforms,\n",
    "        dataset_type ='train'\n",
    "    )\n",
    "    \n",
    "    unlabeled_train_set = UnlabeledDataset(\n",
    "        data_dir = TRAIN_UNLABELED_DIR,\n",
    "        transform = TransformFixMatch(weak = weak_transforms, strong = strong_transforms),\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size = CONFIG['train_batch_size'], \n",
    "        shuffle = True,\n",
    "        num_workers = CONFIG['num_workers'], \n",
    "        pin_memory = True\n",
    "    )\n",
    "    \n",
    "    unlabeled_train_loader = DataLoader(\n",
    "        unlabeled_train_set,\n",
    "        batch_size = CONFIG['train_batch_size'], \n",
    "        shuffle = True,\n",
    "        num_workers = CONFIG['num_workers'], \n",
    "        pin_memory = True\n",
    "    )\n",
    "\n",
    "    val_set = CustomDataset(\n",
    "        csv_path = os.path.join(ROOT_DIR, 'train_annotations.csv'),\n",
    "        data_dir = TRAIN_LABELED_DIR,\n",
    "        transform = test_transforms,\n",
    "        dataset_type ='val'\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size = CONFIG['val_batch_size'], \n",
    "        shuffle = False,\n",
    "        num_workers = CONFIG['num_workers'], \n",
    "        pin_memory = True\n",
    "    )\n",
    "\n",
    "    return train_loader, unlabeled_train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70115cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.919633Z",
     "iopub.status.busy": "2023-07-15T08:49:55.918849Z",
     "iopub.status.idle": "2023-07-15T08:49:55.931031Z",
     "shell.execute_reply": "2023-07-15T08:49:55.930136Z"
    },
    "papermill": {
     "duration": 0.024176,
     "end_time": "2023-07-15T08:49:55.933051",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.908875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fixmatch_epoch(model, train_loader, unlabeled_train_loader, device, optimizer, epoch):\n",
    "    criterion_labeled = nn.CrossEntropyLoss()\n",
    "    criterion_unlabeled = nn.CrossEntropyLoss(reduction='none') # loss per example\n",
    "\n",
    "    threshold = 0.90 # predictions smaller than 90% confidence are filtered.\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0.0\n",
    "    dataset_size = 0\n",
    "    \n",
    "    bar = tqdm(enumerate(unlabeled_train_loader), total=len(unlabeled_train_loader), colour='cyan', file=sys.stdout)\n",
    "\n",
    "    labeled_iterator = iter(train_loader)\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, unlabeled_images in bar:\n",
    "\n",
    "        unlabeled_images_weak, unlabeled_images_strong = unlabeled_images['img']\n",
    "\n",
    "        unlabeled_images_weak = unlabeled_images_weak.to(device)\n",
    "        unlabeled_images_strong = unlabeled_images_strong.to(device)\n",
    "        try:\n",
    "          labeled_data = next(labeled_iterator)\n",
    "        except StopIteration as e:\n",
    "          labeled_iterator = iter(train_loader)\n",
    "          labeled_data = next(labeled_iterator)\n",
    "\n",
    "        labeled_images = labeled_data['img']\n",
    "        labels = labeled_data['label']\n",
    "\n",
    "        labeled_images = labeled_images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_labeled = model(labeled_images)\n",
    "\n",
    "        # get pseudo-labels, don't propagate gradients\n",
    "        with torch.no_grad():\n",
    "          pred_weak = model(unlabeled_images_weak)\n",
    "\n",
    "          # get confidence as a probability\n",
    "          pred_weak_confidence = torch.nn.functional.softmax(pred_weak, dim = -1)\n",
    "          max_values, max_indices = torch.max(pred_weak_confidence, dim = -1)\n",
    "\n",
    "          # filter out unconfident predictions\n",
    "          fixmatch_mask = (max_values > threshold).float()\n",
    "\n",
    "        pred_strong = model(unlabeled_images_strong)\n",
    "\n",
    "        loss_labeled = criterion_labeled(pred_labeled, labels)\n",
    "        loss_consistency = criterion_unlabeled(pred_strong, max_indices) * fixmatch_mask\n",
    "        loss_consistency = loss_consistency.mean()\n",
    "\n",
    "        loss = loss_labeled + loss_consistency\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, LabeledLoss=loss_labeled.item(), ConsistencyLoss = loss_consistency.item(), FractionMasked=(1 - fixmatch_mask.float().mean()).item())\n",
    "\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc07e0c",
   "metadata": {
    "papermill": {
     "duration": 0.00914,
     "end_time": "2023-07-15T08:49:55.951280",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.942140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Create model </h4>\n",
    "You should experiment with different models by modifying existing ones or constructing new models from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68cc2895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.971628Z",
     "iopub.status.busy": "2023-07-15T08:49:55.970723Z",
     "iopub.status.idle": "2023-07-15T08:49:55.977295Z",
     "shell.execute_reply": "2023-07-15T08:49:55.976556Z"
    },
    "papermill": {
     "duration": 0.018475,
     "end_time": "2023-07-15T08:49:55.979227",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.960752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResnetModel, self).__init__()\n",
    "        self.backbone = resnet18()\n",
    "        \n",
    "        # Change the classification head to have num_classes output neurons\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features=in_features, out_features=num_classes, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300003bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:55.998532Z",
     "iopub.status.busy": "2023-07-15T08:49:55.997884Z",
     "iopub.status.idle": "2023-07-15T08:49:59.336215Z",
     "shell.execute_reply": "2023-07-15T08:49:59.335191Z"
    },
    "papermill": {
     "duration": 3.350253,
     "end_time": "2023-07-15T08:49:59.338413",
     "exception": false,
     "start_time": "2023-07-15T08:49:55.988160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResnetModel(num_classes=CONFIG['num_classes'])\n",
    "model.to(CONFIG['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0798c9",
   "metadata": {
    "papermill": {
     "duration": 0.009482,
     "end_time": "2023-07-15T08:49:59.357561",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.348079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Training Helpers </h4>\n",
    "You are encouraged to experiment with different scheduler types and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36bdd5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:59.378716Z",
     "iopub.status.busy": "2023-07-15T08:49:59.377833Z",
     "iopub.status.idle": "2023-07-15T08:49:59.384187Z",
     "shell.execute_reply": "2023-07-15T08:49:59.383268Z"
    },
    "papermill": {
     "duration": 0.019205,
     "end_time": "2023-07-15T08:49:59.386286",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.367081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CONFIG['step_size'], gamma=CONFIG['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a3745",
   "metadata": {
    "papermill": {
     "duration": 0.009223,
     "end_time": "2023-07-15T08:49:59.405343",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.396120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Training function </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727a7c2",
   "metadata": {
    "papermill": {
     "duration": 0.009351,
     "end_time": "2023-07-15T08:49:59.424458",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.415107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Validation function </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c89ae15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:59.444783Z",
     "iopub.status.busy": "2023-07-15T08:49:59.444038Z",
     "iopub.status.idle": "2023-07-15T08:49:59.452650Z",
     "shell.execute_reply": "2023-07-15T08:49:59.451770Z"
    },
    "papermill": {
     "duration": 0.020771,
     "end_time": "2023-07-15T08:49:59.454692",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.433921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    total_val_loss = 0.0\n",
    "    dataset_size = 0\n",
    "    \n",
    "    correct = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
    "    for step, data in bar:\n",
    "        images = data['img'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        \n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        \n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        total_val_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = np.round(total_val_loss / dataset_size, 2)\n",
    "    \n",
    "        accuracy = np.round(100 * correct / dataset_size, 2)\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Valid_Acc=accuracy, Valid_Loss=epoch_loss)\n",
    "\n",
    "    return accuracy, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0687c8f",
   "metadata": {
    "papermill": {
     "duration": 0.009137,
     "end_time": "2023-07-15T08:49:59.472872",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.463735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Build submission file </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "504e5962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:59.493284Z",
     "iopub.status.busy": "2023-07-15T08:49:59.492436Z",
     "iopub.status.idle": "2023-07-15T08:49:59.500198Z",
     "shell.execute_reply": "2023-07-15T08:49:59.499396Z"
    },
    "papermill": {
     "duration": 0.019803,
     "end_time": "2023-07-15T08:49:59.502110",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.482307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_submission(model, dataloader, device, submission_file):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_image_names = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        images = data['img'].to(device)\n",
    "        img_names = data['img_name']\n",
    "        pred = model(images)\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        \n",
    "        predicted = predicted.cpu().numpy().tolist()\n",
    "        all_predictions.extend(predicted)\n",
    "        all_image_names.extend(img_names)\n",
    "    \n",
    "    all_predictions = [index_to_class_mapping[prediction] for prediction in all_predictions]\n",
    "    data = list(zip(all_image_names, all_predictions))\n",
    "    submission_df = pd.DataFrame(data=data, columns=['image_name', 'class_name'])\n",
    "    submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"Submission saved to {submission_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa859787",
   "metadata": {
    "papermill": {
     "duration": 0.009339,
     "end_time": "2023-07-15T08:49:59.521024",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.511685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4> Run Training </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6991108d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:59.542611Z",
     "iopub.status.busy": "2023-07-15T08:49:59.541838Z",
     "iopub.status.idle": "2023-07-15T08:49:59.548971Z",
     "shell.execute_reply": "2023-07-15T08:49:59.548111Z"
    },
    "papermill": {
     "duration": 0.020284,
     "end_time": "2023-07-15T08:49:59.551244",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.530960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(model, device, optimizer, num_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    top_accuracy = 0.0\n",
    "    \n",
    "    train_loader, unlabeled_train_loader, val_loader = prepare_loaders()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss = train_fixmatch_epoch(model, train_loader, unlabeled_train_loader, device, optimizer, num_epochs)\n",
    "        with torch.no_grad():\n",
    "            val_accuracy, val_loss = valid_epoch(model, val_loader, device, epoch)\n",
    "            if val_accuracy > top_accuracy:\n",
    "                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n",
    "                top_accuracy = val_accuracy\n",
    "                torch.save(model.state_dict(), SAVE_PATH)\n",
    "                print(\"Model Saved\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee08b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:59.572191Z",
     "iopub.status.busy": "2023-07-15T08:49:59.571383Z",
     "iopub.status.idle": "2023-07-15T08:58:02.338330Z",
     "shell.execute_reply": "2023-07-15T08:58:02.337046Z"
    },
    "papermill": {
     "duration": 482.779732,
     "end_time": "2023-07-15T08:58:02.340663",
     "exception": false,
     "start_time": "2023-07-15T08:49:59.560931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: Tesla T4\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [01:02<00:00,  1.50it/s, ConsistencyLoss=0.0138, Epoch=10, FractionMasked=0, LabeledLoss=3.22]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:01<00:00,  2.95it/s, Epoch=0, Valid_Acc=3.17, Valid_Loss=35.1]\n",
      "Validation Accuracy Improved (0.0 ---> 3.17)\n",
      "Model Saved\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:46<00:00,  2.02it/s, ConsistencyLoss=0.000162, Epoch=10, FractionMasked=0, LabeledLoss=3.03]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.67it/s, Epoch=1, Valid_Acc=8.83, Valid_Loss=12.6]\n",
      "Validation Accuracy Improved (3.17 ---> 8.83)\n",
      "Model Saved\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:45<00:00,  2.07it/s, ConsistencyLoss=4.86e-5, Epoch=10, FractionMasked=0, LabeledLoss=2.95]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.52it/s, Epoch=2, Valid_Acc=8.67, Valid_Loss=5.74]\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:45<00:00,  2.07it/s, ConsistencyLoss=6.32e-5, Epoch=10, FractionMasked=0, LabeledLoss=2.76]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.17it/s, Epoch=3, Valid_Acc=8.67, Valid_Loss=7.19]\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:45<00:00,  2.08it/s, ConsistencyLoss=0.000159, Epoch=10, FractionMasked=0, LabeledLoss=2.78]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.67it/s, Epoch=4, Valid_Acc=7.33, Valid_Loss=8.53]\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:46<00:00,  2.03it/s, ConsistencyLoss=0.000125, Epoch=10, FractionMasked=0, LabeledLoss=2.89]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.33it/s, Epoch=5, Valid_Acc=9.83, Valid_Loss=14.6]\n",
      "Validation Accuracy Improved (8.83 ---> 9.83)\n",
      "Model Saved\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:44<00:00,  2.09it/s, ConsistencyLoss=5.33e-5, Epoch=10, FractionMasked=0, LabeledLoss=2.9]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.37it/s, Epoch=6, Valid_Acc=10, Valid_Loss=5.43]\n",
      "Validation Accuracy Improved (9.83 ---> 10.0)\n",
      "Model Saved\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:46<00:00,  2.04it/s, ConsistencyLoss=5.32e-5, Epoch=10, FractionMasked=0, LabeledLoss=2.81]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.54it/s, Epoch=7, Valid_Acc=11, Valid_Loss=6.25]\n",
      "Validation Accuracy Improved (10.0 ---> 11.0)\n",
      "Model Saved\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:44<00:00,  2.12it/s, ConsistencyLoss=6.29e-5, Epoch=10, FractionMasked=0, LabeledLoss=2.57]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  7.00it/s, Epoch=8, Valid_Acc=9, Valid_Loss=7.52]\n",
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 94/94 [00:44<00:00,  2.09it/s, ConsistencyLoss=0.000285, Epoch=10, FractionMasked=0, LabeledLoss=2.55]\n",
      "100%|\u001b[36m██████████\u001b[0m| 5/5 [00:00<00:00,  6.10it/s, Epoch=9, Valid_Acc=13.5, Valid_Loss=4.48]\n",
      "Validation Accuracy Improved (11.0 ---> 13.5)\n",
      "Model Saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_training(model, CONFIG['device'],optimizer, CONFIG['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79b2e82c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:58:02.826088Z",
     "iopub.status.busy": "2023-07-15T08:58:02.825624Z",
     "iopub.status.idle": "2023-07-15T08:58:06.401744Z",
     "shell.execute_reply": "2023-07-15T08:58:06.400683Z"
    },
    "papermill": {
     "duration": 3.821563,
     "end_time": "2023-07-15T08:58:06.403962",
     "exception": false,
     "start_time": "2023-07-15T08:58:02.582399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model for submission\n",
      "Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading best model for submission\")\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "\n",
    "test_set = UnlabeledDataset(TEST_DIR, test_transforms)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size = CONFIG['val_batch_size'], \n",
    "        shuffle = False,\n",
    "        num_workers = CONFIG['num_workers'], \n",
    "        pin_memory = True\n",
    ")\n",
    "\n",
    "build_submission(model, test_loader, CONFIG['device'], 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 509.163357,
   "end_time": "2023-07-15T08:58:09.093924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-15T08:49:39.930567",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
